Evaluation Results
----------------

### Raw data
Here you can find the raw data used in our evaluation.

 - Data used for the research question related to effectiveness (RQ1): [no-threshold](data/RQ1-no-threshold.csv) and [with-threshold](data/RQ1-threshold.csv)
 - Data used for the research question related to training sample size (RQ2): [no-threshold](data/RQ2-no-threshold.csv) and [with-threshold](data/RQ2-threshold.csv)
 - Data used for the research question related to the flaky category (RQ3): [no-threshold](data/RQ3-no-threshold.csv) and [with-threshold](data/RQ3-threshold.csv)
  - Data used for the research question related to efficiency (RQ4): [time](data/RQ4-time.csv) and [storage overhead](data/RQ4-memory.csv)

### Evaluation Datasets
<img src="img/tab_datasets.png" width="50%">

---
### [RQ1] How effective is FLAST in predicting test flakiness?
<img src="img/boxplots.png" width="50%">
<img src="img/cm.png" width="50%">
<img src="img/tab_effectiveness_efficiency.png" width="100%">

---
### [RQ2] How does FLAST effectiveness vary with the size of the train sample?
<img src="img/training_size.png" width="50%">

---
### [RQ3] How effective is FLAST in identifying a flaky test category?
<img src="img/categories.png" width="50%">

---
### [RQ5] How does FLAST compare with other state-of-the-art techniques?
<img src="img/tab_qualitative.png" width="100%">
